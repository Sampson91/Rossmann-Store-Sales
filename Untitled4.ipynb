{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import visuals as vs\n",
    "import datetime\n",
    "import csv\n",
    "# import xgboost as xgb\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import cross_validation\n",
    "from matplotlib import pylab as plt\n",
    "plot = True\n",
    "goal = 'Sales'\n",
    "myid = 'Id'\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "1      2          5  2015-07-31   6064        625     1      1            0   \n",
       "2      3          5  2015-07-31   8314        821     1      1            0   \n",
       "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
       "4      5          5  2015-07-31   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1115 entries, 0 to 1114\n",
      "Data columns (total 10 columns):\n",
      "Store                        1115 non-null int64\n",
      "StoreType                    1115 non-null object\n",
      "Assortment                   1115 non-null object\n",
      "CompetitionDistance          1112 non-null float64\n",
      "CompetitionOpenSinceMonth    761 non-null float64\n",
      "CompetitionOpenSinceYear     761 non-null float64\n",
      "Promo2                       1115 non-null int64\n",
      "Promo2SinceWeek              571 non-null float64\n",
      "Promo2SinceYear              571 non-null float64\n",
      "PromoInterval                571 non-null object\n",
      "dtypes: float64(5), int64(2), object(3)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#商店数据查看\n",
    "store = pd.read_csv('./store.csv')\n",
    "rossm = pd.merge(sales,store,on='Store')\n",
    "rossm_test = pd.merge(test,store,on='Store')\n",
    "store.head()\n",
    "store.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>8314</td>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>13995</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>4822</td>\n",
       "      <td>559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek     Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07   5263        555     1      1            0   \n",
       "1      2          5  2015-07   6064        625     1      1            0   \n",
       "2      3          5  2015-07   8314        821     1      1            0   \n",
       "3      4          5  2015-07  13995       1498     1      1            0   \n",
       "4      5          5  2015-07   4822        559     1      1            0   \n",
       "\n",
       "   SchoolHoliday  Year  Month year_month  \n",
       "0              1  2015      7    2015-07  \n",
       "1              1  2015      7    2015-07  \n",
       "2              1  2015      7    2015-07  \n",
       "3              1  2015      7    2015-07  \n",
       "4              1  2015      7    2015-07  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Year'] = sales['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "sales['Month'] = sales['Date'].apply(lambda x:int(str(x)[5:7]))\n",
    "sales['year_month'] =sales['Date'].apply(lambda x:str(x)[:7])\n",
    "sales['Date'] = sales['Date'].apply(lambda x: (str(x)[:7]))\n",
    "test['Year']  = test['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "test['Month'] = test['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "test['Date']  = test['Date'].apply(lambda x: (str(x)[:7]))\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# start_store=1\n",
    "# end_store = 6\n",
    "# fig,(axis1) = plt.subplots(1,1,figsize=(15,5))\n",
    "# sns.heatmap(store_piv[list(range(start_store,end_store+1))].corr(),annot=True)\n",
    "rossm[rossm['Promo2']!=0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    store = pd.read_csv('./store.csv')\n",
    "    train_org = pd.read_csv('./train.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    test_org = pd.read_csv('./test.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    train = pd.merge(train_org,store,on='Store',how='left')\n",
    "    test = pd.merge(test_org,store,on='Store',how='left')\n",
    "    \n",
    "    features1 = ['Id', 'Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', \n",
    "                 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', \n",
    "                 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', \n",
    "                 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "    feature_non = ['Promo','Store','Date', 'StateHoliday','SchoolHoliday', 'StoreType', 'Assortment', 'Promo2', 'PromoInterval']\n",
    "    return (train,test,features1,feature_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train,test,features,features_no):\n",
    "    train = train[train['Open']==1]\n",
    "    \n",
    "    test = test[test['Open']==1]\n",
    "    for rossm in [train,test]:\n",
    "        rossm['year'] = rossm.Date.apply(lambda x: int(x.split('-')[0]))\n",
    "        rossm['month']= rossm.Date.apply(lambda x: int(x.split('-')[1]))\n",
    "        rossm['day']  = rossm.Date.apply(lambda x: int(x.split('-')[2]))\n",
    "\n",
    "        rossm['promojan'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jan' in x else 0)\n",
    "        rossm['promofeb'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Feb' in x else 0)\n",
    "        rossm['promomar'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Mar' in x else 0)\n",
    "        rossm['promoapr'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Apr' in x else 0)\n",
    "        rossm['promomay'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'May' in x else 0)\n",
    "        rossm['promojun'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jun' in x else 0)\n",
    "        rossm['promojul'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jul' in x else 0)\n",
    "        rossm['promoaug'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Aug' in x else 0)\n",
    "        rossm['promosep'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Sep' in x else 0)\n",
    "        rossm['promooct'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Oct' in x else 0)\n",
    "        rossm['promonov'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Nov' in x else 0)\n",
    "        rossm['promodec'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Dec' in x else 0)\n",
    "    \n",
    "    day_dummies = pd.get_dummies(train['DayOfWeek'],prefix='Day')\n",
    "    day_dummies.drop(['Day_7'],axis=1,inplace=True)  #删除周日的数据\n",
    "    train = train.join(day_dummies)\n",
    "\n",
    "    \n",
    "    day_dummies_test = pd.get_dummies(test['DayOfWeek'],prefix='Day')\n",
    "    day_dummies_test.drop(['Day_7'],axis=1,inplace=True)  #删除周日数据\n",
    "    test = test.join(day_dummies_test)\n",
    "    \n",
    "    no_feature = [myid,'Date']\n",
    "    features = set(features) - set(no_feature)\n",
    "    features_no = set(features_no) - set(no_feature)\n",
    "    features = list(features)\n",
    "    features.extend(['year','month','day'])\n",
    "    class DataFrameInputer(TransformerMixin):\n",
    "        def __init__(self):\n",
    "                \"\"\"\n",
    "                \"\"\"\n",
    "        def fit(self,X,y=None):\n",
    "            self.fill = pd.Series([X[c].value_counts().index[0] \n",
    "                                  if X[c].dtype==np.dtype('O') \n",
    "                                   else X[c].mean() for c in X],index = X.columns)\n",
    "            return self\n",
    "        def transform(self,X,y=None):\n",
    "            return X.fillna(self.fill)\n",
    "        \n",
    "    train = DataFrameInputer().fit_transform(train)\n",
    "    test  = DataFrameInputer().fit_transform(test)\n",
    "        \n",
    "    le = LabelEncoder()\n",
    "    for col in features:\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    for col in set(features) - set(features_no) - set([]):\n",
    "        try:\n",
    "            scaler.fit(list(train[col])+list(test[col]))\n",
    "        except:\n",
    "            print(col)\n",
    "        train[col] = scaler.transform(train[col])\n",
    "        test[col] = scaler.transform(test[col])\n",
    "    return (train,test,features,features_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=['Store','DayOfWeek','Sales','Open','Promo','StateHoliday','SchoolHoliday','StoreType','Assortment','CompetitionDistance','promo_competer']\n",
    "feature1 =['Store','DayOfWeek','Open','Promo','StateHoliday','SchoolHoliday','StoreType','Assortment','CompetitionDistance','promo_competer']\n",
    "rossm['promo_competer']=0\n",
    "rossm['promo_competer'] = rossm[rossm['Promo2']==1]['Promo2SinceYear']-rossm[rossm['Promo2']==1]['CompetitionOpenSinceYear']+(rossm[rossm['Promo2']==1]['Promo2SinceWeek']/52)-(rossm[rossm['Promo2']==1]['CompetitionOpenSinceMonth']/12)\n",
    "rossm_test['promo_competer'] = rossm_test[rossm_test['Promo2']==1]['Promo2SinceYear']-rossm_test[rossm_test['Promo2']==1]['CompetitionOpenSinceYear']+(rossm_test[rossm_test['Promo2']==1]['Promo2SinceWeek']/52)-(rossm_test[rossm_test['Promo2']==1]['CompetitionOpenSinceMonth']/12)\n",
    "rossm[feature].head(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,features,features_non_numeric = get_data()\n",
    "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
    "train.drop(['Open','Date','DayOfWeek'],axis=1,inplace=True)\n",
    "test.drop(['Open','Date','DayOfWeek','Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rossm_train = dict(list(train.groupby('Store')))\n",
    "rossm_test = dict(list(test.groupby('Store')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-64-71ddfe60ac0e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-71ddfe60ac0e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for i in rossm_train:\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for i in rossm_test:\n",
    "    store = rossm_train[i]\n",
    "    y = store['Sales']\n",
    "    x = store.drop(['Sales','Store'],axis=1)\n",
    "    X_trian,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division \n",
    "\n",
    "greater_percent = 0.5\n",
    "\n",
    "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
    "B = 0.5\n",
    "accuracy = greater_percent/100\n",
    "recall=1\n",
    "# TODO： 使用上面的公式，并设置beta=0.5计算F-score\n",
    "fscore = (1+B*B)*(accuracy*recall)/((B*B*accuracy)+recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression 0.95624359627\n",
      "RandomForestRegressor 0.954630536703\n",
      "LogisticRegression 0.459199233524\n",
      "DecisionTreeRegressor 0.918038277283\n"
     ]
    }
   ],
   "source": [
    "store = rossm_train[2]\n",
    "y = store['Sales']\n",
    "x = store.drop(['Sales','Store'],axis=1)\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
    "\n",
    "clf_a = LinearRegression()\n",
    "clf_a.fit(X_train,y_train)\n",
    "clf_a.predict(X_test)\n",
    "print('LinearRegression',r2_score(clf_a.predict(X_test),y_test))\n",
    "clf_b = RandomForestRegressor()\n",
    "clf_b.fit(X_train,y_train)\n",
    "print('RandomForestRegressor',r2_score(clf_b.predict(X_test),y_test))\n",
    "clf_c = LogisticRegression()\n",
    "clf_c.fit(X_train,y_train)\n",
    "print('LogisticRegression',r2_score(clf_c.predict(X_test),y_test))\n",
    "clf_d = tree.DecisionTreeRegressor()\n",
    "clf_d.fit(X_train,y_train)\n",
    "print('DecisionTreeRegressor',r2_score(clf_d.predict(X_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression trained on 5 samples.\n",
      "LinearRegression trained on 54 samples.\n",
      "LinearRegression trained on 545 samples.\n",
      "RandomForestRegressor trained on 5 samples.\n",
      "RandomForestRegressor trained on 54 samples.\n",
      "RandomForestRegressor trained on 545 samples.\n",
      "GaussianNB trained on 5 samples.\n",
      "GaussianNB trained on 54 samples.\n",
      "GaussianNB trained on 545 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "clf_a = LinearRegression()\n",
    "clf_b = RandomForestRegressor()\n",
    "clf_c = GaussianNB()\n",
    "\n",
    "#计算1%，10%，100%到训练数据分别对应多少点\n",
    "samples_1 = int(len(X_train)*0.01)\n",
    "samples_10 = int(len(X_train)*0.1)\n",
    "samples_100 = int(len(X_train))\n",
    "result = {}\n",
    "\n",
    "for clf in [clf_a,clf_b,clf_c]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    result[clf_name] = {}\n",
    "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
    "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "import visuals as vs\n",
      "import datetime\n",
      "import csv\n",
      "import xgboost as xgb\n",
      "import itertools\n",
      "import os\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
      "from sklearn.base import TransformerMixin\n",
      "from sklearn import cross_validation\n",
      "from matplotlib import pylab as plt\n",
      "plot = True\n",
      "goal = 'Sales'\n",
      "myid = 'Id'\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import tree\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "train,test,features,features_non_numeric = get_data()\n",
      "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
      "train.drop(['Open','Date','DayOfWeek'],axis=1,inplace=True)\n",
      "test.drop(['Open','Date','DayOfWeek','Id'],axis=1,inplace=True)\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "import visuals as vs\n",
      "import datetime\n",
      "import csv\n",
      "# import xgboost as xgb\n",
      "import itertools\n",
      "import os\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "get_ipython().magic('matplotlib inline')\n",
      "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
      "from sklearn.base import TransformerMixin\n",
      "from sklearn import cross_validation\n",
      "from matplotlib import pylab as plt\n",
      "plot = True\n",
      "goal = 'Sales'\n",
      "myid = 'Id'\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import tree\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "sales = pd.read_csv('./train.csv')\n",
      "test = pd.read_csv('./test.csv')\n",
      "sales.head()\n",
      "#商店数据查看\n",
      "store = pd.read_csv('./store.csv')\n",
      "rossm = pd.merge(sales,store,on='Store')\n",
      "rossm_test = pd.merge(test,store,on='Store')\n",
      "store.head()\n",
      "store.info()\n",
      "def get_data():\n",
      "    store = pd.read_csv('./store.csv')\n",
      "    train_org = pd.read_csv('./train.csv',dtype={'StateHoliday':pd.np.string_})\n",
      "    test_org = pd.read_csv('./test.csv',dtype={'StateHoliday':pd.np.string_})\n",
      "    train = pd.merge(train_org,store,on='Store',how='left')\n",
      "    test = pd.merge(test_org,store,on='Store',how='left')\n",
      "    \n",
      "    features1 = ['Id', 'Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', \n",
      "                 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', \n",
      "                 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', \n",
      "                 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "\n",
      "    feature_non = ['Promo','Store','Date', 'StateHoliday','SchoolHoliday', 'StoreType', 'Assortment', 'Promo2', 'PromoInterval']\n",
      "    return (train,test,features1,feature_non)\n",
      "def process_data(train,test,features,features_no):\n",
      "    train = train[train['Open']==1]\n",
      "    \n",
      "    test = test[test['Open']==1]\n",
      "    for rossm in [train,test]:\n",
      "        rossm['year'] = rossm.Date.apply(lambda x: int(x.split('-')[0]))\n",
      "        rossm['month']= rossm.Date.apply(lambda x: int(x.split('-')[1]))\n",
      "        rossm['day']  = rossm.Date.apply(lambda x: int(x.split('-')[2]))\n",
      "\n",
      "        rossm['promojan'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jan' in x else 0)\n",
      "        rossm['promofeb'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Feb' in x else 0)\n",
      "        rossm['promomar'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Mar' in x else 0)\n",
      "        rossm['promoapr'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Apr' in x else 0)\n",
      "        rossm['promomay'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'May' in x else 0)\n",
      "        rossm['promojun'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jun' in x else 0)\n",
      "        rossm['promojul'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jul' in x else 0)\n",
      "        rossm['promoaug'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Aug' in x else 0)\n",
      "        rossm['promosep'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Sep' in x else 0)\n",
      "        rossm['promooct'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Oct' in x else 0)\n",
      "        rossm['promonov'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Nov' in x else 0)\n",
      "        rossm['promodec'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Dec' in x else 0)\n",
      "    \n",
      "    day_dummies = pd.get_dummies(train['DayOfWeek'],prefix='Day')\n",
      "    day_dummies.drop(['Day_7'],axis=1,inplace=True)  #删除周日的数据\n",
      "    train = train.join(day_dummies)\n",
      "\n",
      "    \n",
      "    day_dummies_test = pd.get_dummies(test['DayOfWeek'],prefix='Day')\n",
      "    day_dummies_test.drop(['Day_7'],axis=1,inplace=True)  #删除周日数据\n",
      "    test = test.join(day_dummies_test)\n",
      "    \n",
      "    no_feature = [myid,'Date']\n",
      "    features = set(features) - set(no_feature)\n",
      "    features_no = set(features_no) - set(no_feature)\n",
      "    features = list(features)\n",
      "    features.extend(['year','month','day'])\n",
      "    class DataFrameInputer(TransformerMixin):\n",
      "        def __init__(self):\n",
      "                \"\"\"\n",
      "                \"\"\"\n",
      "        def fit(self,X,y=None):\n",
      "            self.fill = pd.Series([X[c].value_counts().index[0] \n",
      "                                  if X[c].dtype==np.dtype('O') \n",
      "                                   else X[c].mean() for c in X],index = X.columns)\n",
      "            return self\n",
      "        def transform(self,X,y=None):\n",
      "            return X.fillna(self.fill)\n",
      "        \n",
      "    train = DataFrameInputer().fit_transform(train)\n",
      "    test  = DataFrameInputer().fit_transform(test)\n",
      "        \n",
      "    le = LabelEncoder()\n",
      "    for col in features:\n",
      "        le.fit(list(train[col])+list(test[col]))\n",
      "        train[col] = le.transform(train[col])\n",
      "        test[col] = le.transform(test[col])\n",
      "        \n",
      "    scaler = StandardScaler()\n",
      "    for col in set(features) - set(features_no) - set([]):\n",
      "        try:\n",
      "            scaler.fit(list(train[col])+list(test[col]))\n",
      "        except:\n",
      "            print(col)\n",
      "        train[col] = scaler.transform(train[col])\n",
      "        test[col] = scaler.transform(test[col])\n",
      "    return (train,test,features,features_no)\n",
      "train,test,features,features_non_numeric = get_data()\n",
      "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
      "train.drop(['Open','Date','DayOfWeek'],axis=1,inplace=True)\n",
      "test.drop(['Open','Date','DayOfWeek','Id'],axis=1,inplace=True)\n",
      "rossm_train = dict(list(train.groupby('Store')))\n",
      "rossm_test = dict(list(test.groupby('Store')))\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    mnb_count = GaussianNB()\n",
      "    mnb_count.fit(X_train, y_train)\n",
      "\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = accuracy_score(y_train.iloc[:300], predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = fbeta_score(y_train.iloc[:300], predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = fbeta_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print \"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size)\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    mnb_count = GaussianNB()\n",
      "    mnb_count.fit(X_train, y_train)\n",
      "\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = accuracy_score(y_train.iloc[:300], predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = fbeta_score(y_train.iloc[:300], predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = fbeta_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = accuracy_score(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = fbeta_score(y_train, predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = fbeta_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LogisticRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = KNeighborsClassifier()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_trian,y_train)\n",
      "t_predict = clf.predict(X_test)\n",
      "accuracy_score(y_test,t_predict)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "t_predict = clf.predict(X_test)\n",
      "accuracy_score(y_test,t_predict)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "clf.score(y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "clf.score(clf.predict(X_test),y_test)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score,mean_squared_error,r2_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = mean_squared_error(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = mean_squared_error(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = r2_score(y_train, predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = r2_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score,mean_squared_error,r2_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = mean_squared_error(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = mean_squared_error(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = r2_score(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = r2_score(y_test, predictions_test)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(result)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "\n",
      "vs.evaluate(result)\n",
      "from __future__ import division \n",
      "# TODO：总的记录数\n",
      "n_records = len(store)\n",
      "\n",
      "# TODO：被调查者的收入大于$50,000的人数\n",
      "n_greater_50k = len(clear_shangfei[clear_shangfei['data_quality']==0])\n",
      "\n",
      "# TODO：被调查者的收入最多为$50,000的人数\n",
      "n_at_most_50k = len(clear_shangfei[clear_shangfei['data_quality']==192])\n",
      "\n",
      "# TODO：被调查者收入大于$50,000所占的比例\n",
      "greater_percent = (n_greater_50k/n_records)*100\n",
      "\n",
      "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
      "B = 0.5\n",
      "accuracy = greater_percent/100\n",
      "recall=1\n",
      "# TODO： 使用上面的公式，并设置beta=0.5计算F-score\n",
      "fscore = (1+B*B)*(accuracy*recall)/((B*B*accuracy)+recall) \n",
      "from __future__ import division \n",
      "\n",
      "greater_percent = 0.5\n",
      "\n",
      "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
      "B = 0.5\n",
      "accuracy = greater_percent/100\n",
      "recall=1\n",
      "# TODO： 使用上面的公式，并设置beta=0.5计算F-score\n",
      "fscore = (1+B*B)*(accuracy*recall)/((B*B*accuracy)+recall) \n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "clf.score(y_test)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "\n",
      "vs.evaluate(result,accuracy, fscore)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score,mean_squared_error,r2_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['mse_train'] = mean_squared_error(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['mse_test'] = mean_squared_error(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['r2_train'] = r2_score(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['r2_test'] = r2_score(y_test, predictions_test)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "def evaluate(results, accuracy, f1):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53),                loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "def evaluate(results):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53),                loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "import matplotlib.pyplot as pl\n",
      "import matplotlib.patches as mpatches\n",
      "import numpy as np\n",
      "def evaluate(results):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53),                loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "import matplotlib.pyplot as pl\n",
      "import matplotlib.patches as mpatches\n",
      "import numpy as np\n",
      "def evaluate(results):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53),                loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "r2_score(clf.predict(X_test),y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print r2_score(clf_a.predict(X_test),y_test)\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print r2_score(clf_b.predict(X_test),y_test)\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print r2_score(clf_c.predict(X_test),y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print(r2_score(clf_a.predict(X_test),y_test))\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print(r2_score(clf_b.predict(X_test),y_test))\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print(r2_score(clf_c.predict(X_test),y_test))\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn import tree\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print(r2_score(clf_a.predict(X_test),y_test))\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print(r2_score(clf_b.predict(X_test),y_test))\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print(r2_score(clf_c.predict(X_test),y_test))\n",
      "clf_d = tree.DecisionTreeRegressor()\n",
      "clf_d.fit(X_train,y_train)\n",
      "print(r2_score(clf_d.predict(X_test),y_test))\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print('LinearRegression',r2_score(clf_a.predict(X_test),y_test))\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print('RandomForestRegressor',r2_score(clf_b.predict(X_test),y_test))\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print('LogisticRegression',r2_score(clf_c.predict(X_test),y_test))\n",
      "clf_d = tree.DecisionTreeRegressor()\n",
      "clf_d.fit(X_train,y_train)\n",
      "print('DecisionTreeRegressor',r2_score(clf_d.predict(X_test),y_test))\n",
      "for line in locals()['In']:\n",
      "    print(line)\n",
      "get_ipython().magic('history')\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "import visuals as vs\n",
      "import datetime\n",
      "import csv\n",
      "import xgboost as xgb\n",
      "import itertools\n",
      "import os\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "%matplotlib inline\n",
      "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
      "from sklearn.base import TransformerMixin\n",
      "from sklearn import cross_validation\n",
      "from matplotlib import pylab as plt\n",
      "plot = True\n",
      "goal = 'Sales'\n",
      "myid = 'Id'\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import tree\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "train,test,features,features_non_numeric = get_data()\n",
      "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
      "train.drop(['Open','Date','DayOfWeek'],axis=1,inplace=True)\n",
      "test.drop(['Open','Date','DayOfWeek','Id'],axis=1,inplace=True)\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "import visuals as vs\n",
      "import datetime\n",
      "import csv\n",
      "# import xgboost as xgb\n",
      "import itertools\n",
      "import os\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "%matplotlib inline\n",
      "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
      "from sklearn.base import TransformerMixin\n",
      "from sklearn import cross_validation\n",
      "from matplotlib import pylab as plt\n",
      "plot = True\n",
      "goal = 'Sales'\n",
      "myid = 'Id'\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn import tree\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "sales = pd.read_csv('./train.csv')\n",
      "test = pd.read_csv('./test.csv')\n",
      "sales.head()\n",
      "#商店数据查看\n",
      "store = pd.read_csv('./store.csv')\n",
      "rossm = pd.merge(sales,store,on='Store')\n",
      "rossm_test = pd.merge(test,store,on='Store')\n",
      "store.head()\n",
      "store.info()\n",
      "def get_data():\n",
      "    store = pd.read_csv('./store.csv')\n",
      "    train_org = pd.read_csv('./train.csv',dtype={'StateHoliday':pd.np.string_})\n",
      "    test_org = pd.read_csv('./test.csv',dtype={'StateHoliday':pd.np.string_})\n",
      "    train = pd.merge(train_org,store,on='Store',how='left')\n",
      "    test = pd.merge(test_org,store,on='Store',how='left')\n",
      "    \n",
      "    features1 = ['Id', 'Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', \n",
      "                 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', \n",
      "                 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', \n",
      "                 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
      "\n",
      "    feature_non = ['Promo','Store','Date', 'StateHoliday','SchoolHoliday', 'StoreType', 'Assortment', 'Promo2', 'PromoInterval']\n",
      "    return (train,test,features1,feature_non)\n",
      "def process_data(train,test,features,features_no):\n",
      "    train = train[train['Open']==1]\n",
      "    \n",
      "    test = test[test['Open']==1]\n",
      "    for rossm in [train,test]:\n",
      "        rossm['year'] = rossm.Date.apply(lambda x: int(x.split('-')[0]))\n",
      "        rossm['month']= rossm.Date.apply(lambda x: int(x.split('-')[1]))\n",
      "        rossm['day']  = rossm.Date.apply(lambda x: int(x.split('-')[2]))\n",
      "\n",
      "        rossm['promojan'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jan' in x else 0)\n",
      "        rossm['promofeb'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Feb' in x else 0)\n",
      "        rossm['promomar'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Mar' in x else 0)\n",
      "        rossm['promoapr'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Apr' in x else 0)\n",
      "        rossm['promomay'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'May' in x else 0)\n",
      "        rossm['promojun'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jun' in x else 0)\n",
      "        rossm['promojul'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jul' in x else 0)\n",
      "        rossm['promoaug'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Aug' in x else 0)\n",
      "        rossm['promosep'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Sep' in x else 0)\n",
      "        rossm['promooct'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Oct' in x else 0)\n",
      "        rossm['promonov'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Nov' in x else 0)\n",
      "        rossm['promodec'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Dec' in x else 0)\n",
      "    \n",
      "    day_dummies = pd.get_dummies(train['DayOfWeek'],prefix='Day')\n",
      "    day_dummies.drop(['Day_7'],axis=1,inplace=True)  #删除周日的数据\n",
      "    train = train.join(day_dummies)\n",
      "\n",
      "    \n",
      "    day_dummies_test = pd.get_dummies(test['DayOfWeek'],prefix='Day')\n",
      "    day_dummies_test.drop(['Day_7'],axis=1,inplace=True)  #删除周日数据\n",
      "    test = test.join(day_dummies_test)\n",
      "    \n",
      "    no_feature = [myid,'Date']\n",
      "    features = set(features) - set(no_feature)\n",
      "    features_no = set(features_no) - set(no_feature)\n",
      "    features = list(features)\n",
      "    features.extend(['year','month','day'])\n",
      "    class DataFrameInputer(TransformerMixin):\n",
      "        def __init__(self):\n",
      "                \"\"\"\n",
      "                \"\"\"\n",
      "        def fit(self,X,y=None):\n",
      "            self.fill = pd.Series([X[c].value_counts().index[0] \n",
      "                                  if X[c].dtype==np.dtype('O') \n",
      "                                   else X[c].mean() for c in X],index = X.columns)\n",
      "            return self\n",
      "        def transform(self,X,y=None):\n",
      "            return X.fillna(self.fill)\n",
      "        \n",
      "    train = DataFrameInputer().fit_transform(train)\n",
      "    test  = DataFrameInputer().fit_transform(test)\n",
      "        \n",
      "    le = LabelEncoder()\n",
      "    for col in features:\n",
      "        le.fit(list(train[col])+list(test[col]))\n",
      "        train[col] = le.transform(train[col])\n",
      "        test[col] = le.transform(test[col])\n",
      "        \n",
      "    scaler = StandardScaler()\n",
      "    for col in set(features) - set(features_no) - set([]):\n",
      "        try:\n",
      "            scaler.fit(list(train[col])+list(test[col]))\n",
      "        except:\n",
      "            print(col)\n",
      "        train[col] = scaler.transform(train[col])\n",
      "        test[col] = scaler.transform(test[col])\n",
      "    return (train,test,features,features_no)\n",
      "train,test,features,features_non_numeric = get_data()\n",
      "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
      "train.drop(['Open','Date','DayOfWeek'],axis=1,inplace=True)\n",
      "test.drop(['Open','Date','DayOfWeek','Id'],axis=1,inplace=True)\n",
      "rossm_train = dict(list(train.groupby('Store')))\n",
      "rossm_test = dict(list(test.groupby('Store')))\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    mnb_count = GaussianNB()\n",
      "    mnb_count.fit(X_train, y_train)\n",
      "\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = accuracy_score(y_train.iloc[:300], predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = fbeta_score(y_train.iloc[:300], predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = fbeta_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print \"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size)\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    mnb_count = GaussianNB()\n",
      "    mnb_count.fit(X_train, y_train)\n",
      "\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)[:300]\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = accuracy_score(y_train.iloc[:300], predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = fbeta_score(y_train.iloc[:300], predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = fbeta_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = accuracy_score(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = accuracy_score(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = fbeta_score(y_train, predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = fbeta_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LogisticRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = KNeighborsClassifier()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = LogisticRegression()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_trian,y_train)\n",
      "t_predict = clf.predict(X_test)\n",
      "accuracy_score(y_test,t_predict)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "t_predict = clf.predict(X_test)\n",
      "accuracy_score(y_test,t_predict)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "clf.score(y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "clf.score(clf.predict(X_test),y_test)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score,mean_squared_error,r2_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = mean_squared_error(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = mean_squared_error(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = r2_score(y_train, predictions_train,beta=0.5)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = r2_score(y_test, predictions_test,beta=0.5)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score,mean_squared_error,r2_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['acc_train'] = mean_squared_error(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['acc_test'] = mean_squared_error(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['f_train'] = r2_score(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['f_test'] = r2_score(y_test, predictions_test)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(results)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "\n",
      "vs.evaluate(result)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "\n",
      "vs.evaluate(result)\n",
      "from __future__ import division \n",
      "# TODO：总的记录数\n",
      "n_records = len(store)\n",
      "\n",
      "# TODO：被调查者的收入大于$50,000的人数\n",
      "n_greater_50k = len(clear_shangfei[clear_shangfei['data_quality']==0])\n",
      "\n",
      "# TODO：被调查者的收入最多为$50,000的人数\n",
      "n_at_most_50k = len(clear_shangfei[clear_shangfei['data_quality']==192])\n",
      "\n",
      "# TODO：被调查者收入大于$50,000所占的比例\n",
      "greater_percent = (n_greater_50k/n_records)*100\n",
      "\n",
      "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
      "B = 0.5\n",
      "accuracy = greater_percent/100\n",
      "recall=1\n",
      "# TODO： 使用上面的公式，并设置beta=0.5计算F-score\n",
      "fscore = (1+B*B)*(accuracy*recall)/((B*B*accuracy)+recall)\n",
      "from __future__ import division \n",
      "\n",
      "greater_percent = 0.5\n",
      "\n",
      "from sklearn.metrics import accuracy_score, fbeta_score, precision_score, recall_score\n",
      "B = 0.5\n",
      "accuracy = greater_percent/100\n",
      "recall=1\n",
      "# TODO： 使用上面的公式，并设置beta=0.5计算F-score\n",
      "fscore = (1+B*B)*(accuracy*recall)/((B*B*accuracy)+recall)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "clf.score(y_test)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "\n",
      "vs.evaluate(result,accuracy, fscore)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "# TODO：从sklearn中导入两个评价指标 - fbeta_score和accuracy_score\n",
      "from sklearn.metrics import fbeta_score, accuracy_score,mean_squared_error,r2_score\n",
      "import time\n",
      "\n",
      "\n",
      "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test):\n",
      "    '''\n",
      "    inputs:\n",
      "       - learner: the learning algorithm to be trained and predicted on\n",
      "       - sample_size: the size of samples (number) to be drawn from training set\n",
      "       - X_train: features training set\n",
      "       - y_train: income training set\n",
      "       - X_test: features testing set\n",
      "       - y_test: income testing set\n",
      "    '''\n",
      "\n",
      "    results = {}\n",
      "\n",
      "    # TODO：使用sample_size大小的训练数据来拟合学习器\n",
      "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    learner.fit(X_train.iloc[:sample_size, :], y_train.iloc[:sample_size])\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算训练时间\n",
      "    results['train_time'] = (end - start)\n",
      "\n",
      "    # TODO: 得到在测试集上的预测值\n",
      "    #       然后得到对前300个训练数据的预测结果\n",
      "    start = time.clock()  # 获得程序开始时间\n",
      "    predictions_test = learner.predict(X_test)\n",
      "    predictions_train = learner.predict(X_train)\n",
      "    end = time.clock()  # 获得程序结束时间\n",
      "\n",
      "    # TODO：计算预测用时\n",
      "    results['pred_time'] = end - start\n",
      "\n",
      "    # TODO：得到在最前面的300个训练数据的预测结果\n",
      "    predictions_train = learner.predict(X_train)\n",
      "\n",
      "    # TODO：计算预测时间\n",
      "    results['test_time'] = end - start\n",
      "\n",
      "    # TODO：计算在最前面的300个训练数据的准确率\n",
      "    results['mse_train'] = mean_squared_error(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算在测试集上的准确率\n",
      "    results['mse_test'] = mean_squared_error(y_test, predictions_test)\n",
      "\n",
      "    # TODO：计算在最前面300个训练数据上的F-score\n",
      "    results['r2_train'] = r2_score(y_train, predictions_train)\n",
      "\n",
      "    # TODO：计算测试集上的F-score\n",
      "    results['r2_test'] = r2_score(y_test, predictions_test)\n",
      "\n",
      "    # 成功\n",
      "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
      "\n",
      "    # 返回结果\n",
      "    return results\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "def evaluate(results, accuracy, f1):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53), \\\n",
      "               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "def evaluate(results):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53), \\\n",
      "               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_10 = int(len(X_train)*0.10)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "import matplotlib.pyplot as pl\n",
      "import matplotlib.patches as mpatches\n",
      "import numpy as np\n",
      "def evaluate(results):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53), \\\n",
      "               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "import matplotlib.pyplot as pl\n",
      "import matplotlib.patches as mpatches\n",
      "import numpy as np\n",
      "def evaluate(results):\n",
      "    \"\"\"\n",
      "    Visualization code to display results of various learners.\n",
      "    \n",
      "    inputs:\n",
      "      - learners: a list of supervised learners\n",
      "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
      "      - accuracy: The score for the naive predictor\n",
      "      - f1: The score for the naive predictor\n",
      "    \"\"\"\n",
      "  \n",
      "    # Create figure\n",
      "    fig, ax = pl.subplots(2, 3, figsize = (11,7))\n",
      "\n",
      "    # Constants\n",
      "    bar_width = 0.3\n",
      "    colors = ['#A00000','#00A0A0','#00A000']\n",
      "    \n",
      "    # Super loop to plot four panels of data\n",
      "    for k, learner in enumerate(results.keys()):\n",
      "        for j, metric in enumerate(['train_time', 'acc_train', 'f_train', 'pred_time', 'acc_test', 'f_test']):\n",
      "            for i in np.arange(3):\n",
      "                \n",
      "                # Creative plot code\n",
      "                ax[j/3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
      "                ax[j/3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
      "                ax[j/3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
      "                ax[j/3, j%3].set_xlabel(\"Training Set Size\")\n",
      "                ax[j/3, j%3].set_xlim((-0.1, 3.0))\n",
      "    \n",
      "    # Add unique y-labels\n",
      "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[0, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[0, 2].set_ylabel(\"F-score\")\n",
      "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
      "    ax[1, 1].set_ylabel(\"Accuracy Score\")\n",
      "    ax[1, 2].set_ylabel(\"F-score\")\n",
      "    \n",
      "    # Add titles\n",
      "    ax[0, 0].set_title(\"Model Training\")\n",
      "    ax[0, 1].set_title(\"Accuracy Score on Training Subset\")\n",
      "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
      "    ax[1, 0].set_title(\"Model Predicting\")\n",
      "    ax[1, 1].set_title(\"Accuracy Score on Testing Set\")\n",
      "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
      "    \n",
      "#     # Add horizontal lines for naive predictors\n",
      "#     ax[0, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 1].axhline(y = accuracy, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "#     ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
      "    \n",
      "    # Set y-limits for score panels\n",
      "    ax[0, 1].set_ylim((0, 1))\n",
      "    ax[0, 2].set_ylim((0, 1))\n",
      "    ax[1, 1].set_ylim((0, 1))\n",
      "    ax[1, 2].set_ylim((0, 1))\n",
      "\n",
      "    # Create patches for the legend\n",
      "    patches = []\n",
      "    for i, learner in enumerate(results.keys()):\n",
      "        patches.append(mpatches.Patch(color = colors[i], label = learner))\n",
      "    pl.legend(handles = patches, bbox_to_anchor = (-.80, 2.53), \\\n",
      "               loc = 'upper center', borderaxespad = 0., ncol = 3, fontsize = 'x-large')\n",
      "    \n",
      "    # Aesthetics\n",
      "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
      "    pl.tight_layout()\n",
      "    pl.show()\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "evaluate(result)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "result\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf = LinearRegression()\n",
      "clf.fit(X_train,y_train)\n",
      "clf.predict(X_test)\n",
      "r2_score(clf.predict(X_test),y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print r2_score(clf_a.predict(X_test),y_test)\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print r2_score(clf_b.predict(X_test),y_test)\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print r2_score(clf_c.predict(X_test),y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print(r2_score(clf_a.predict(X_test),y_test))\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print(r2_score(clf_b.predict(X_test),y_test))\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print(r2_score(clf_c.predict(X_test),y_test))\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn import tree\n",
      "clf_a = LinearRegression()\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_c = GaussianNB()\n",
      "\n",
      "#计算1%，10%，100%到训练数据分别对应多少点\n",
      "samples_1 = int(len(X_train)*0.01)\n",
      "samples_10 = int(len(X_train)*0.1)\n",
      "samples_100 = int(len(X_train))\n",
      "result = {}\n",
      "\n",
      "for clf in [clf_a,clf_b,clf_c]:\n",
      "    clf_name = clf.__class__.__name__\n",
      "    result[clf_name] = {}\n",
      "    for i,samples in enumerate([samples_1,samples_10,samples_100]):\n",
      "        result[clf_name][i] = train_predict(clf,samples,X_train,y_train,X_test,y_test)\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print(r2_score(clf_a.predict(X_test),y_test))\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print(r2_score(clf_b.predict(X_test),y_test))\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print(r2_score(clf_c.predict(X_test),y_test))\n",
      "clf_d = tree.DecisionTreeRegressor()\n",
      "clf_d.fit(X_train,y_train)\n",
      "print(r2_score(clf_d.predict(X_test),y_test))\n",
      "store = rossm_train[2]\n",
      "y = store['Sales']\n",
      "x = store.drop(['Sales','Store'],axis=1)\n",
      "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
      "\n",
      "clf_a = LinearRegression()\n",
      "clf_a.fit(X_train,y_train)\n",
      "clf_a.predict(X_test)\n",
      "print('LinearRegression',r2_score(clf_a.predict(X_test),y_test))\n",
      "clf_b = RandomForestRegressor()\n",
      "clf_b.fit(X_train,y_train)\n",
      "print('RandomForestRegressor',r2_score(clf_b.predict(X_test),y_test))\n",
      "clf_c = LogisticRegression()\n",
      "clf_c.fit(X_train,y_train)\n",
      "print('LogisticRegression',r2_score(clf_c.predict(X_test),y_test))\n",
      "clf_d = tree.DecisionTreeRegressor()\n",
      "clf_d.fit(X_train,y_train)\n",
      "print('DecisionTreeRegressor',r2_score(clf_d.predict(X_test),y_test))\n",
      "for line in locals()['In']:\n",
      "    print(line)\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "for line in locals()['In']:\n",
    "    print(line)\n",
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
