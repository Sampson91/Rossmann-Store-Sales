{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sampson/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import visuals as vs\n",
    "import datetime\n",
    "import csv\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "import os\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn import grid_search\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import cross_validation\n",
    "from matplotlib import pylab as plt\n",
    "plot = True\n",
    "goal = 'Sales'\n",
    "myid = 'Id'\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data():  ## 数据获取函数\n",
    "    store = pd.read_csv('./store.csv')\n",
    "    train_org = pd.read_csv('./train.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    test_org = pd.read_csv('./test.csv',dtype={'StateHoliday':pd.np.string_})\n",
    "    train = pd.merge(train_org,store,on='Store',how='left')\n",
    "    test = pd.merge(test_org,store,on='Store',how='left')\n",
    "    \n",
    "    features1 = ['Id', 'Store', 'DayOfWeek', 'Date', 'Open', 'Promo', 'StateHoliday', \n",
    "                 'SchoolHoliday', 'StoreType', 'Assortment', 'CompetitionDistance', \n",
    "                 'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2', \n",
    "                 'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "    feature_non = ['Promo','Store','Date', 'StateHoliday','SchoolHoliday', 'StoreType', 'Assortment', 'Promo2', 'PromoInterval']\n",
    "    return (train,test,features1,feature_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train,test,features,features_no): ##数据处理\n",
    "    train = train[train['Open']==1]\n",
    "    \n",
    "    test = test[test['Open']==1]\n",
    "    for rossm in [train,test]:\n",
    "        rossm['year'] = rossm.Date.apply(lambda x: int(x.split('-')[0]))\n",
    "        rossm['month']= rossm.Date.apply(lambda x: int(x.split('-')[1]))\n",
    "        rossm['day']  = rossm.Date.apply(lambda x: int(x.split('-')[2]))\n",
    "\n",
    "        rossm['promojan'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jan' in x else 0)\n",
    "        rossm['promofeb'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Feb' in x else 0)\n",
    "        rossm['promomar'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Mar' in x else 0)\n",
    "        rossm['promoapr'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Apr' in x else 0)\n",
    "        rossm['promomay'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'May' in x else 0)\n",
    "        rossm['promojun'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jun' in x else 0)\n",
    "        rossm['promojul'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Jul' in x else 0)\n",
    "        rossm['promoaug'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Aug' in x else 0)\n",
    "        rossm['promosep'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Sep' in x else 0)\n",
    "        rossm['promooct'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Oct' in x else 0)\n",
    "        rossm['promonov'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Nov' in x else 0)\n",
    "        rossm['promodec'] = rossm.PromoInterval.apply(lambda x:0 if isinstance(x,float) else 1 if 'Dec' in x else 0)\n",
    "    \n",
    "    day_dummies = pd.get_dummies(train['DayOfWeek'],prefix='Day')\n",
    "    day_dummies.drop(['Day_7'],axis=1,inplace=True)  #删除周日的数据\n",
    "    train = train.join(day_dummies)\n",
    "\n",
    "    \n",
    "    day_dummies_test = pd.get_dummies(test['DayOfWeek'],prefix='Day')\n",
    "    day_dummies_test.drop(['Day_7'],axis=1,inplace=True)  #删除周日数据\n",
    "    test = test.join(day_dummies_test)\n",
    "    \n",
    "    noisy_features = [myid,'Date']\n",
    "    features = [c for c in features if c not in noisy_features]\n",
    "    features_non_numeric = [c for c in features_no if c not in noisy_features]\n",
    "    features.extend(['year','month','day'])\n",
    "    class DataFrameInputer(TransformerMixin):\n",
    "        def __init__(self):\n",
    "                \"\"\"\n",
    "                \"\"\"\n",
    "        def fit(self,X,y=None):\n",
    "            self.fill = pd.Series([X[c].value_counts().index[0] \n",
    "                                  if X[c].dtype==np.dtype('O') \n",
    "                                   else X[c].mean() for c in X],index = X.columns)\n",
    "            return self\n",
    "        def transform(self,X,y=None):\n",
    "            return X.fillna(self.fill)\n",
    "        \n",
    "    train = DataFrameInputer().fit_transform(train)\n",
    "    test  = DataFrameInputer().fit_transform(test)\n",
    "        \n",
    "    le = LabelEncoder()\n",
    "    for col in features:\n",
    "        le.fit(list(train[col])+list(test[col]))\n",
    "        train[col] = le.transform(train[col])\n",
    "        test[col] = le.transform(test[col])\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    for col in set(features) - set(features_no) - set([]):\n",
    "        try:\n",
    "            scaler.fit(list(train[col])+list(test[col]))\n",
    "        except:\n",
    "            print(col)\n",
    "        train[col] = scaler.transform(train[col])\n",
    "        test[col] = scaler.transform(test[col])\n",
    "    return (train,test,features,features_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test,features,features_non_numeric = get_data()\n",
    "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
    "# train.drop(['Open','Date','DayOfWeek'],axis=1,inplace=True)\n",
    "# test.drop(['Open','Date','DayOfWeek'],axis=1,inplace=True)\n",
    "rossm_train = dict(list(train.groupby('Store')))\n",
    "rossm_test = dict(list(test.groupby('Store')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test,features,features_non_numeric = get_data()\n",
    "train,test,features,features_non_numeric = process_data(train,test,features,features_non_numeric)\n",
    "a1 = train.columns\n",
    "a2 = ['Date','Sales','Customers','DayOfWeek']\n",
    "a1 = [f for f in a1 if f not in a2]\n",
    "# XGB_native(train,test,a1,features_non_numeric)\n",
    "rossm_train = dict(list(train.groupby('Store')))\n",
    "rossm_test = dict(list(test.groupby('Store')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method RandomForestRegressor.score of RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=13,\n",
      "           max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=70, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)>\n",
      "-0.704077194552\n"
     ]
    }
   ],
   "source": [
    "store = train\n",
    "y = store['Sales']\n",
    "x = store.drop(['Sales','Store','Customers','Date'],axis=1)\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=70,max_features='sqrt',max_depth=13)\n",
    "clf.fit(X_train,y_train)\n",
    "print clf.score\n",
    "print r2_score(clf.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RandomForest 参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821572935275\n"
     ]
    }
   ],
   "source": [
    "clf_b = RandomForestRegressor()\n",
    "paramer = {'n_estimators':[10,20],'max_features':['auto','sqrt'],\n",
    "           'max_depth':[7,15,20],\"bootstrap\": [True, False]}\n",
    "gs = grid_search.GridSearchCV(clf_b,paramer,n_jobs=-1,cv=2)\n",
    "gs.fit(X_train,y_train)\n",
    "\n",
    "print r2_score(gs.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'auto', 'n_estimators': 90, 'bootstrap': True, 'max_depth': 11}\n",
      "0.70088964412\n"
     ]
    }
   ],
   "source": [
    "store = rossm_train[8]\n",
    "y = store['Sales']\n",
    "x = store.drop(['Sales','Store','Customers','Date'],axis=1)\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
    "clf_b = RandomForestRegressor()\n",
    "paramer = {'n_estimators':[10,20,30,40,50,60,70,80,90,100],'max_features':['auto','sqrt'],\n",
    "           'max_depth':range(6,15),\"bootstrap\": [True, False]}\n",
    "gs = grid_search.GridSearchCV(clf_b,paramer,n_jobs=-1,cv=2)\n",
    "gs.fit(X_train,y_train)\n",
    "print gs.best_params_\n",
    "print r2_score(gs.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930088444242578"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random1 = []\n",
    "xgb1 = []\n",
    "\n",
    "random2 = []\n",
    "xgb2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in rossm_test:\n",
    "    store = rossm_train[i]\n",
    "    y = store['Sales']\n",
    "    x = store.drop(['Sales','Store','Customers','Date'],axis=1)\n",
    "    X_train,X_test,y_train,y_test = cross_validation.train_test_split(x,y,test_size=0.3)\n",
    "    \n",
    "    clf_b = RandomForestRegressor()\n",
    "    paramer = {'n_estimators':[60,70,80],'max_features':['auto'],\n",
    "               'max_depth':range(10,13),\"bootstrap\": [True]}\n",
    "    gs = grid_search.GridSearchCV(clf_b,paramer,n_jobs=-1,cv=2)\n",
    "    gs.fit(X_train,y_train)\n",
    "    random1.append(gs.best_score_)\n",
    "    random2.append(r2_score(gs.predict(X_test),y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665965750294 0.589146638467\n"
     ]
    }
   ],
   "source": [
    "print np.mean(random1),np.mean(random2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "##### RandomForestRegressor最优参数的结果0.589146638467没有xgboost算法没有调惨的0.626765270346分数高，\n",
    "##### 最终选择xgboost算法为最终建模算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
